# I have a PLAN

## 研究名称

针对智能生成代码的安全性检测方案构建与Solidity等多语言环境下的实证研究

Secode: A Security Testing Framework for AI-Generated Code and Empirical Research in Multilingual Environments with Emphasis on Solidity

## 研究背景及目标

在当前大数据时代，生成式大语言模型（例如chatGPT）在代码生成领域的应用呈现出日益增长的趋势。生成式代码的广泛应用将在未来塑造软件开发的格局，然而这些生成式模型可能产生潜在的漏洞和安全隐患，影响到软件系统的稳定性和安全性。截至本项目成员所知，目前尚未提出一种针对生成式代码的正确性和安全性检测的系统性和规范化的方法。因此，本项目组成员计划设计一种高度规范化的方法，旨在确保其在多语言环境下的正确性并揭示生成式大语言模型生成的代码中的安全隐患。本方案不仅关注解决特定语言生成检测问题，更致力于泛化生成式代码安全性研究和实践应用。基于该规范化检测方案，项目成员分析了生成代码在合约导向式语言 Solidity 及多种其他常用语言上的正确性及安全性并进行了统计学分析与研究。

## 研究贡献

我们的研究主要有如下几点贡献：

- 提出了Secode:一项针对智能生成代码的规范化安全性检测方案。我们分别设计了可面向多语言的正确性和安全性方案。
- 针对某种语言的安全性检测，我们提出了如何基于常见漏洞数据集智能生成测试代码。在尽可能不对生成式模型进行错误引导的情况下检测其是否会产生特定类型的漏洞。
- 提出了规范化效率评估的统计学模型
- 利用收集到的漏洞集，针对chatGPT3.5生成 Solidity 语言的准确性和安全性进行了方案实测，得出了——(todo)结论。同时我们针对verilog等其他语言进行了实测分析，结果证实我们的方案可以高效准确地评估特定语言的准确性和安全性，且对多种语言都有较好的适应性。
- 本质是代码安全检测方法的应用，场景是大模型。此方法可以推广至任何需要检测代码安全的场景中
